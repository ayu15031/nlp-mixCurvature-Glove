{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64c89e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove.pkl     glove.pt      gloveMixed.pt mixed.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd5480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glove\n",
    "import run\n",
    "import pickle\n",
    "from tools import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
<<<<<<< HEAD
   "id": "50825be4",
=======
   "id": "ee722163",
>>>>>>> 3a705e4705e2b39d9b81efcd36bfc5721a62e7f7
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 128\n",
    "CONTEXT_SIZE = 3\n",
    "NUM_EPOCH = 100\n",
    "BATHC_SIZE = 512\n",
    "PATH = \"../model/gloveMixed.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
<<<<<<< HEAD
   "id": "27a7f799",
=======
   "id": "9a57b7a7",
>>>>>>> 3a705e4705e2b39d9b81efcd36bfc5721a62e7f7
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/f.pkl\", mode='rb') as fp:\n",
    "    doc = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
<<<<<<< HEAD
   "id": "630c3aec",
=======
   "id": "995c1bdc",
>>>>>>> 3a705e4705e2b39d9b81efcd36bfc5721a62e7f7
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary()\n",
    "dictionary.update(doc)\n",
    "# doc.vocab_size\n",
    "VS = dictionary.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
<<<<<<< HEAD
   "id": "d9184a0e",
=======
   "id": "feb7f80d",
>>>>>>> 3a705e4705e2b39d9b81efcd36bfc5721a62e7f7
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21281"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dictionary.word2idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee7673d3",
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C euc 0.0, hyp -0.5, sph 0.5\n"
     ]
    },
    {
>>>>>>> 3a705e4705e2b39d9b81efcd36bfc5721a62e7f7
     "data": {
      "text/plain": [
       "GloVeMixedCurvature(\n",
       "  (euc): ManifoldEmbedding(\n",
       "    (_focal_embeddings): Embedding(21281, 128)\n",
       "    (_context_embeddings): Embedding(21281, 128)\n",
       "    (_focal_biases): Embedding(21281, 1)\n",
       "    (_context_biases): Embedding(21281, 1)\n",
       "    (manifold): Stereographic manifold\n",
       "  )\n",
       "  (hyp): ManifoldEmbedding(\n",
       "    (_focal_embeddings): Embedding(21281, 128)\n",
       "    (_context_embeddings): Embedding(21281, 128)\n",
       "    (_focal_biases): Embedding(21281, 1)\n",
       "    (_context_biases): Embedding(21281, 1)\n",
       "    (manifold): Stereographic manifold\n",
       "  )\n",
       "  (sph): ManifoldEmbedding(\n",
       "    (_focal_embeddings): Embedding(21281, 128)\n",
       "    (_context_embeddings): Embedding(21281, 128)\n",
       "    (_focal_biases): Embedding(21281, 1)\n",
       "    (_context_biases): Embedding(21281, 1)\n",
       "    (manifold): Stereographic manifold\n",
       "  )\n",
       "  (_focal_embeddings): Embedding(21281, 128)\n",
       "  (_context_embeddings): Embedding(21281, 128)\n",
       "  (_focal_biases): Embedding(21281, 1)\n",
       "  (_context_biases): Embedding(21281, 1)\n",
       ")"
      ]
     },
<<<<<<< HEAD
     "execution_count": 7,
=======
     "execution_count": 8,
>>>>>>> 3a705e4705e2b39d9b81efcd36bfc5721a62e7f7
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = glove.GloVeMixedCurvature(EMBEDDING_SIZE, CONTEXT_SIZE, VS)\n",
    "model.load_state_dict(torch.load(PATH, map_location=torch.device('cpu')))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "id": "7cb1f89c",
=======
   "execution_count": 10,
   "id": "54e2ff60",
>>>>>>> 3a705e4705e2b39d9b81efcd36bfc5721a62e7f7
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'euc': 0.058570027351379395, 'hyp': 1.0, 'sph': 1.0}\n",
      "{'euc': 0.9999939, 'hyp': 5.7713128e-06, 'sph': 3.5080123e-07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/hdjj6v6x4x5crg2lctj_26cr0000gn/T/ipykernel_78349/2681497438.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ws = torch.nn.functional.softmax(model.w)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/w6ds_szn4333rz0srzmb5drh0000gn/T/ipykernel_89426/2681497438.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ws = torch.nn.functional.softmax(model.w)\n"
     ]
    }
   ],
   "source": [
    "ws = torch.nn.functional.softmax(model.w)\n",
    "\n",
    "curvatures = {\n",
    "    'euc': float(model.euc.manifold.k.data.detach().numpy()),\n",
    "    'hyp': float(model.hyp.manifold.k.data.detach().numpy()),\n",
    "    'sph': float(model.sph.manifold.k.data.detach().numpy()),\n",
    "} \n",
    "\n",
    "weights = {\n",
    "    'euc': ws.detach().numpy()[0],\n",
    "    'hyp': ws.detach().numpy()[1],\n",
    "    'sph': ws.detach().numpy()[2],\n",
    "} \n",
    "\n",
    "print(curvatures)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "0d5baf93",
=======
   "execution_count": 12,
   "id": "50bf8931",
>>>>>>> 3a705e4705e2b39d9b81efcd36bfc5721a62e7f7
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = [\n",
    "    model.euc._focal_embeddings.weight + model.euc._context_embeddings.weight,\n",
    "    model.hyp._focal_embeddings.weight + model.hyp._context_embeddings.weight,\n",
    "    model.sph._focal_embeddings.weight + model.sph._context_embeddings.weight,\n",
    "]\n",
    "emb = [e.detach().numpy() for e in emb]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "bb4204f5",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 13,
   "id": "175c21ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21281, 128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 3a705e4705e2b39d9b81efcd36bfc5721a62e7f7
   "source": [
    "emb[0].shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "222cfcc3",
=======
   "execution_count": 14,
   "id": "b5819ae2",
>>>>>>> 3a705e4705e2b39d9b81efcd36bfc5721a62e7f7
   "metadata": {},
   "outputs": [],
   "source": [
    "mixedGlove = {}\n",
    "for w in dictionary.word2idx:\n",
    "    mixedGlove[w] = {\n",
    "        \"euc\":emb[0][dictionary.word2idx[w]],\n",
    "        \"hyp\":emb[1][dictionary.word2idx[w]],\n",
    "        \"sph\":emb[2][dictionary.word2idx[w]],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "b285515c",
=======
   "execution_count": 15,
   "id": "09c3facb",
>>>>>>> 3a705e4705e2b39d9b81efcd36bfc5721a62e7f7
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = {\n",
    "    \"curvatures\": curvatures,\n",
    "    \"weights\": weights,\n",
    "    \"vecs\": mixedGlove,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "a2c92839",
=======
   "execution_count": 16,
   "id": "824a2da3",
>>>>>>> 3a705e4705e2b39d9b81efcd36bfc5721a62e7f7
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "a3b82160",
=======
   "execution_count": 17,
   "id": "b3d49d0e",
>>>>>>> 3a705e4705e2b39d9b81efcd36bfc5721a62e7f7
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/mixed.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(embedding, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd0274a",
   "metadata": {},
   "source": [
    "# Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c22f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogy_mix(word_a, word_b, word_c, embeddings_list, curvatures, weights):\n",
    "    word_a = word_a.lower()\n",
    "    word_b = word_b.lower()\n",
    "    word_c = word_c.lower()\n",
    "    \n",
    "    final = {}\n",
    "    words = embeddings_list[0].keys()\n",
    "    word_dist = []\n",
    "    parallen_transes = []\n",
    "    for i in range(len(curvatures)):\n",
    "\n",
    "        e_a, e_b, e_c = embeddings_list[i][word_a], embeddings_list[i][word_b], embeddings_list[i][word_c]\n",
    "\n",
    "        parallen_trans = mobmath.mobius_add(e_c, mobmath.gyration(e_c, -e_a, mobmath.mobius_add(-e_a, e_b, k=curvatures[i]), k=curvatures[i]), k=curvatures[i])\n",
    "        parallen_transes.append(parallen_trans)\n",
    "\n",
    "    for w in words:\n",
    "        \n",
    "        if w in [word_a, word_b, word_c]:\n",
    "                continue\n",
    "\n",
    "        dist = 0.0\n",
    "    \n",
    "        for i, embeddings in enumerate(embeddings_list):\n",
    "            e_a, e_b, e_c = embeddings[word_a], embeddings[word_b], embeddings[word_c]\n",
    "\n",
    "            c = curvatures[i]\n",
    "            wt = weights[i]\n",
    "            parallen_trans = parallen_transes[i]\n",
    "\n",
    "            # cosine_sim = find_distance(embeddings[w], mobmath.mobius_add(e_c, )   ()find_distance(e_b, e_a), find_distance(, e_c))\n",
    "            # parallen_trans = self.moebius_add_mat(pos_emb[1], self.gyr_mat(pos_emb[1], -neg_emb, self.moebius_add_mat(-neg_emb, pos_emb[0])))\n",
    "\n",
    "            distance = find_distance(embeddings[w], parallen_trans, c)\n",
    "            dist += wt * distance\n",
    "            # if distance > max_cosine_sim:\n",
    "                # max_cosine_sim = distance\n",
    "                # best_word = w\n",
    "            \n",
    "        word_dist.append((dist, w))\n",
    "\n",
    "    word_dist = sorted(word_dist)\n",
    "    final = word_dist[:10]\n",
    "    return final\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
